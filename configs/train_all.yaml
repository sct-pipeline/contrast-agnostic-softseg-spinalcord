seed: 50
save_test_preds: False

directories:
  # Path to the saved models directory
  models_dir: /home/GRAMES.POLYMTL.CA/u114716/contrast-agnostic/saved_models/lifelong
  # Path to the saved results directory
  results_dir: /home/GRAMES.POLYMTL.CA/u114716/contrast-agnostic/results/models_lifelong
  # Path to the saved wandb logs directory
  # if None, starts training from scratch. Otherwise, resumes training from the specified wandb run folder
  wandb_run_folder: None

dataset:
  # Dataset name (will be used as "group_name" for wandb logging)
  name: contrast-agnostic-v3
  # Path to the dataset directory containing all datalists (.json files)
  root_dir: /home/GRAMES.POLYMTL.CA/u114716/contrast-agnostic/datalists/v2-final-aggregation-20241017

preprocessing:
  # Online resampling of images to the specified spacing.
  spacing: [1.0, 1.0, 1.0]
  # Center crop/pad images to the specified size. (NOTE: done after resampling)
  # values correspond to R-L, A-P, I-S axes of the image after 1mm isotropic resampling.
  crop_pad_size: [64, 192, 320]

opt:
  name: adam
  lr: 0.001    # 0.001
  max_epochs: 250
  batch_size: 2
  # Interval between validation checks in epochs
  check_val_every_n_epochs: 50
  # Early stopping patience (this is until patience * check_val_every_n_epochs)
  early_stopping_patience: 20


model:
  # Model architecture to be used for training (also to be specified as args in the command line)
  nnunet-plain:
    # NOTE: these info are typically taken from nnUNetPlans.json (if an nnUNet model is trained)
    n_stages: 6
    features_per_stage: [32, 64, 128, 256, 384, 384]
    n_conv_per_stage: [2, 2, 2, 2, 2, 2]
    n_conv_per_stage_decoder: [2, 2, 2, 2, 2]
    strides: [
      [1, 1, 1],
      [2, 2, 2],
      [2, 2, 2],
      [2, 2, 2],
      [2, 2, 2],
      [1, 2, 2]
    ]
    enable_deep_supervision: True

  nnunet-resencM:
    # NOTE: this uses the new Residual Encoder UNets introduced in nnUNet v2.4.1
    n_stages: 6
    features_per_stage: [32, 64, 128, 256, 384, 384]
    n_blocks_per_stage: [1, 3, 4, 6, 6, 6]
    n_conv_per_stage_decoder: [1, 1, 1, 1, 1]
    strides: [
      [1, 1, 1],
      [2, 2, 2],
      [2, 2, 2],
      [2, 2, 2],
      [2, 2, 2],
      [1, 2, 2],
    ]
    enable_deep_supervision: True
